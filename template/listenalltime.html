<!DOCTYPE html>
<html lang="en">
<head>
  <title>Dashboard (Ouvindo você!)</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.js"></script>
</head>
<body>
    <div class="card text-center">
        <div class="card-header">
            <h1 class="display-6">Busca por voz</h1>
        </div>
        <div class="card-body width:50%">
            <h5 class="card-title">[Escutando o tempo todo] Reconhecimento de Fala</h5>
            <p class="card-text">Essa é uma demonstração simples de como utilizar o Speech Recognition 
                               diretamente no Browser. Esse função é originalmente implementada no Google Chrome e 
                               nos navegadores baseado no Cromium. Portanto, não irá funcionar no Firefox, por exemplo.</p>
            <br>
            <h5>Experimente dizer um dos comandos abaixo, sempre começando por 'MyDash':</h5>
            <p>'vá para o início'</p>
            <p>'vá para projetos'</p>
            <p>'abra o último dashboard'</p> 
          
            <button class="btn btn-warning btn-lg" id="speakbt" onclick="testeSpeechRecognition()">Clique para falar</button>
            <div style="margin-top: 10px;" id="resultSpeak">Retorno</div>
        </div>
        <div class="card-footer text-muted">
          
        </div>

      </div>


    <!--div class="conteiner ">
        <div class="container-fluid">
            <h1 class="display-3 row align-items-center">Busca por voz</h1>
        </div>
        <div class="search">
            <div class="d-grid gap-2 col-2 mx-auto">
                <button class="btn btn-warning btn-lg" id="speakbt" onclick="funcao1()">Buscar</button>
                <div style="margin-top: 10px;" id="resultSpeak">Retorno</div>
            </div>
        </div>
    </div-->
    <script async>
        function testeSpeechRecognition()
        {
            var speakBtn = document.querySelector('#speakbt');
            var resultSpeaker = document.querySelector('#resultSpeak');

            if(window.SpeechRecognition || window.webkitSpeechRecognition){
                var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;

                var mySpeechRecognition = new SpeechRecognition();
                mySpeechRecognition.lang = 'pt-BR';
                
                try{
                    mySpeechRecognition.start();
                    resultSpeaker.innerHTML = "Estou te ouvindo";
                }catch(erro){
                    alert('erro: ' + erro.message );
                }
                
                speakBtn.addEventListener('click', function(){
                    try{
                        mySpeechRecognition.start();
                        resultSpeaker.innerHTML = "Estou te ouvindo";
                    }catch(erro){
                        alert('erro: ' + erro.message );
                    }
                }, false);
                
                mySpeechRecognition.addEventListener('result', function(evt){
                    var resultSpeak = evt.results[0][0].transcript;

                    resultSpeaker.innerHTML = resultSpeak;
                    resultSpeak = resultSpeak.replace(/[.!?,.]/g, "");
                    console.log(resultSpeak.toLowerCase())
                    switch(resultSpeak.toLowerCase()){
                        
                        case 'vá para o início':
                            window.location ='/home';
                            console.log('Vá para Home')
                            break;
                        case 'vá para projetos':
                            window.location ='/projetos';
                            console.log('Vá para projetos')
                            break;
                        case 'abra o último dashboard':
                            window.location ='/dashboard/1';
                            console.log('Vá para Dashboard 1')
                            break;
                    }

                    if (resultSpeak.match(/buscar por/)){

                        resultSpeaker.innerHTML = "Redirecionando...";
                        setTimeout(function(){
                            var resultado = resultSpeak.split('buscar por')
                            window.location.href = 'https://www.gooble.com.br/search?q=' + resultado[1];
                        })
                    }
                }, 2000);

                mySpeechRecognition.addEventListener('error', function(evt){
                    resultSpeaker.innerHTML = 'Se você disse alguma coisa, não ouvi muito bem!'
                });

                
            }else{
                resultSpeaker.innerHTML = "Seu navegador não suporta tanta tecnologia. Considere trocá-lo e tentar novamente.";
            }
        }
    
    </script>
    <script>
        function iAmListening(){

            const magic_word = 'My Dash';

            // initialize our SpeechRecognition object
            let recognition = new webkitSpeechRecognition();
            recognition.lang = 'pt-BR';
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;
            recognition.continuous = true;

            // detect the magic word
            recognition.onresult = e => {
                // extract all the transcripts
                var transcripts  = [].concat.apply([], [...e.results]
                .map(res => [...res]
                    .map(alt => alt.transcript)
                )
                );
                if(transcripts.some(t => t.indexOf(magic_word) > -1)){
                    //do something awesome, like starting your own command listeners
                    alert('Olha o que eu ouvi: '+transcripts);
                }
                else{
                    // didn't understood...
                    console.log('Não entendi...');
                }
            }
            // called when we detect silence
            function stopSpeech(){
                recognition.stop();
                console.log("Parou de ouvir...");
            }
            // called when we detect sound
            function startSpeech(){
                try{ // calling it twice will throw...
                    recognition.start();
                    console.log("Começou a ouvir...");
                }
                catch(e){}
            }
            // request a LocalMediaStream
            navigator.mediaDevices.getUserMedia({audio:true})
            // add our listeners
            .then(stream => detectSilence(stream, stopSpeech, startSpeech))
            .catch(e => log(e.message));


            function detectSilence(
            stream,
            onSoundEnd = _=>{},
            onSoundStart = _=>{},
            silence_delay = 500,
            min_decibels = -80
            ) {
                console.log('Detectou silêncio');
                const ctx = new AudioContext();
                const analyser = ctx.createAnalyser();
                const streamNode = ctx.createMediaStreamSource(stream);
                streamNode.connect(analyser);
                analyser.minDecibels = min_decibels;

                const data = new Uint8Array(analyser.frequencyBinCount); // will hold our data
                let silence_start = performance.now();
                let triggered = false; // trigger only once per silence event

                function loop(time) {
                    testeSpeechRecognition();
                    requestAnimationFrame(loop); // we'll loop every 60th of a second to check
                    analyser.getByteFrequencyData(data); // get current data
                    if (data.some(v => v)) { // if there is data above the given db limit
                        if(triggered){
                            triggered = false;
                            onSoundStart();
                        }
                        silence_start = time; // set it to now
                    }
                    if (!triggered && time - silence_start > silence_delay) {
                        onSoundEnd();
                        triggered = true;
                    }
                }

                loop();
            }
        }
        iAmListening();
    </script>
</body>
</html>